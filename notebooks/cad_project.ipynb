{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Computer-aided diagnosis\n",
    "\n",
    "### Goal:\n",
    "Implement and apply linear regression and logistic regression for measuring nuclei size in histopathology images, and evaluate and analyze the results.  \n",
    "\n",
    "The size of the cell nuclei of the tumor in breast cancer patients can be indicative of the outcome. Large nuclei size indicates more aggressive tumor and in turn worse prognosis for the patient.  As part of their routine work, pathologists make qualitative evaluation of the the size of the nuclei by examining the tissue under a microscope. Quantitative measurement (e.g. by manual segmentation) is a much better solution, however, it is unfeasible as it takes additional time away from the busy pathologists. A solution to this problem is to develop an automatic method for measurement of nuclei area.\n",
    "\n",
    "All data required for this mini-project is provided with the code handout. In the exercises, you applied regression and classification methods on toy datasets, and in the project work you will apply the same methods to a dataset of RGB images of nuclei with size $24\\times24$ pixels. The images originate from the dataset that was previously described in [Veta et al. (2015)](#references). \n",
    "\n",
    "### Deliverables:\n",
    "There is no hard limit for the length of the report, however, concise and short reports are **strongly** encouraged. Aim to present your most important findings in the main body of the report and (if needed) any additional information in an appendix. The following report structure is suggested for the main body of the report:\n",
    "\n",
    "1. Introduction\n",
    "2. Methods\n",
    "3. Results\n",
    "4. Discussion\n",
    "\n",
    "The introduction and result sections can be very brief in this case (e.g. half a page each). The discussion section should contain the analysis of the results.\n",
    "\n",
    "The report must be submitted as a single PDF file. The code must be submitted as a single archive file (e.g. zip) that is self-contained and can be used to reproduce the results in the report. \n",
    "\n",
    "Note that there is not a single correct solution for the project. You have to demonstrate to the reader that you understand the methods that you have studied and can critically analyze the results of applying the methods. Below, you can find a set of assignments (guided project work) that will help you get started with the project work and when correctly completed will present you with a **minimal solution**. Solutions which go beyond these assignments are of course encouraged. \n",
    "\n",
    "Code and a report describing your implementation, results and analysis. \n",
    "\n",
    "### Assessment:\n",
    "The rubric that will be used for assessment of the project work is given in [this table](../rubric.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided project work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear regression for  nuclei area measurement\n",
    "\n",
    "The Python function `nuclei_measurement()` implements training of a linear regression model for measuring the area of nuclei in microscopy images. The dataset for this problem consists of small RGB images of size $24 \\times 24$ pixels with a nucleus in the center. Such images can be obtained, for example, by cropping from larger images after performing a nuclei detection step. The targets are the areas of the  nucleus in the center of the image obtained by manual measurement. The linear regression model that we are going to train will enable us to automatically measure the size of new, previously unseen samples (without resorting to manual measurement).\n",
    "\n",
    "The first section of code loads and prepares the dataset. The data is already split into a training and testing set, each containing more than $20,000$ samples (a validation dataset is not needed as we are not going to perform model selection, i.e. we are going to stick to linear regression). The last few lines of the first section of code visualise the $300$ smallest and $300$ largest nuclei in the training dataset.\n",
    "\n",
    "In this example, we are not going to perform feature extraction but use the raw pixel values as features. Since each sample is an RGB image with size $24 \\times 24$ pixels, we end up with $24 \\times 24 \\times 3=1728$ features. Locate the code that reshapes each image into a feature vector and make sure you understand how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from cad_project import nuclei_measurement\n",
    "\n",
    "nuclei_measurement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the missing functionality for training a linear regression model for automatic measurement of the nuclei area. Evaluate the performance on the independent test dataset.\n",
    "    \n",
    "    The next lines of code plot the predicted vs. the actual area. What is your analysis of the results shown in the plot?\n",
    "    \n",
    "2. Train a new linear regression model with a reduced number of training samples. Which model results in larger error on the testing set and why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic regression for  nuclei classification\n",
    "\n",
    "The Python function `nuclei_classification()` implements the training of a logistic regression model that classifies nuclei into the classes \"large\" (class label $y = 1$) and \"small\" (class label $y = 0$). Examine the code and comments and make sure that you understand what it does. One notable difference from before is that this code uses the analytical expression for the gradient of the loss function, instead of computing it numerically with `ngradient` as before. Using `ngradient` will also work, but is much slower. The script is mostly complete. The only missing component is the values for the parameters of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from cad_project import nuclei_classification\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "nuclei_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select values for the learning rate, batch size and number of iterations (these are sometimes called hyper-parameters of the model), as well as initial values for the model parameters that will result in fast training of an accurate model for this classification problem. Note that if you don't choose the hyper-parameters and initial parameters well, the resulting loss might be out of range of the plot.\n",
    "    \n",
    "    Experiment with a few variations of the parameters and analyse and compare the resulting loss curves. Describe how the different hyper-parameters influence the training process.\n",
    "2. Instead of running gradient descent for a fixed number of iterations, can you propose a stopping criterion for the training?\n",
    "3. Report the classification accuracy for your best trained model.\n",
    "4. Reduce the size of the training set by a very large factor (e.g. 0.5% of the original number of samples). Train the model with this reduced number of samples. Does the model overfit the training dataset? How did you come to this conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "### References\n",
    "Veta M., van Diest P.J., Pluim J.P.W. 2016. Cutting Out the Middleman: Measuring Nuclear Area in Histopathology Slides Without Segmentation. Medical Image Computing and Computer-Assisted Intervention . https://www.doi.org/10.1007/978-3-319-46723-8_73"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
